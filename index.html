<!DOCTYPE html>
<html>
<head>
  <link rel="icon" href="./static/images/icon.png">
  <meta charset="utf-8">
  <meta name="description"
        content="Neural Sign Actors: A diffusion model for 3D sign language production from text">
  <meta name="keywords" content="Sign Language, Hand, 3D, Modeling">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Neural Sign Actors: A diffusion model for 3D sign language production from text</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Neural Sign Actors: A diffusion model for 3D sign language production from text</h1>          
          <div class="is-size-4 publication-authors">
            <span class="author-block"> 
              <a href="">Vasileios Baltatzis</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://rolpotamias.github.io/">Rolandos Alexandros Potamias</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Evangelos Ververas</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Guanxiong Sun</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="">Jiankang Deng</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.imperial.ac.uk/people/s.zafeiriou">Stefanos Zafeiriou</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Imperial College London, United Kingdom</span>
            <span class="author-block"><sup>2</sup>Queenâ€™s University Belfast</span>
          </div>
          <br>
          <span class="author-block">
            <h1 class="title is-size-4  publication-venue">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024</h1>
          </span>
          <br>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2312.02702.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- arXiv Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2112.00585"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
               </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fa fa-database"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/Teaser.png" alt="teaser_fig" class="center">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Sign Languages (SL) serve as the predominant mode of communication for the Deaf and Hard of Hearing communities. The advent of deep learning has aided numerous methods in SL recognition and translation, achieving remarkable results. However, Sign Language Production (SLP) poses a challenge for the computer vision community as the motions generated must be realistic and have precise semantic meanings. Most SLP methods rely on 2D data, thus impeding their ability to attain a necessary level of realism. In this work, we propose a diffusion-based SLP model trained on a curated large-scale dataset of 4D signing avatars and their corresponding text transcripts. The proposed method can generate dynamic sequences of 3D avatars from an unconstrained domain of discourse using a diffusion process formed on a novel and anatomically informed graph neural network defined on the SMPL-X body skeleton. Through a series of quantitative and qualitative experiments, we show that the proposed method considerably outperforms previous methods of SLP. We believe that this work presents an important and necessary step towards realistic neural sign avatars, bridging the communication gap between Deaf and hearing communities.  
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">CVPR 2024 Presentation</h2>
        <div class="publication-video">
          <iframe width="560" height="315" src="" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>

          </iframe>

        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
    <!-- Method overview. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
        <p>
            We present a large scale dataset of American Sign Language.
        </p>
        <div>
            <img src="./static/images/Method_SignLanguage.png" alt="method" class="center">
          </div>
        <p>
           High Quality results blabla
        </p>
          </div>
          <div>
            <img src="./static/images/MainFigure.png" alt="method" class="center">
          </div>
      </div>
    </div>
  </div>
</section>
  
  
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{Baltatzis_2024_CVPR,
      author    = {Baltatzis, Vasileios and Potamias, Rolandos Alexandros and Ververas, Evangelos and Sun, Guanxiong and Deng, Jiankang and Zafeiriou, Stefanos},
      title     = {Neural Sign Actors: A diffusion model for 3D sign language production from text},
      booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
      month     = {June},
      year      = {2024},
      pages     = {}
  }
</code></pre>
  </div>
</section>


<footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              The source code of this website is borrowed from <a
                href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
